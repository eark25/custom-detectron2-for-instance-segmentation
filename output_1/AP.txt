[10/21 22:51:59 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=1333, sample_style='choice')]                         
[10/21 22:51:59 d2.data.common]: Serializing 1129 elements to byte tensors and concatenating them all ...                                                                                                  
[10/21 22:51:59 d2.data.common]: Serialized dataset takes 3.08 MiB                                                                                                                                         
[10/21 22:51:59 d2.evaluation.evaluator]: Start inference on 1129 batches                                                                                                                                  
[10/21 22:52:01 d2.evaluation.evaluator]: Inference done 11/1129. Dataloading: 0.0100 s/iter. Inference: 0.2527 s/iter. Eval: 0.0024 s/iter. Total: 0.2651 s/iter. ETA=0:04:56                             
[10/21 22:52:06 d2.evaluation.evaluator]: Inference done 106/1129. Dataloading: 0.0119 s/iter. Inference: 0.0506 s/iter. Eval: 0.0027 s/iter. Total: 0.0653 s/iter. ETA=0:01:06                            
[10/21 22:52:11 d2.evaluation.evaluator]: Inference done 203/1129. Dataloading: 0.0119 s/iter. Inference: 0.0443 s/iter. Eval: 0.0025 s/iter. Total: 0.0587 s/iter. ETA=0:00:54                            
[10/21 22:52:16 d2.evaluation.evaluator]: Inference done 302/1129. Dataloading: 0.0118 s/iter. Inference: 0.0418 s/iter. Eval: 0.0023 s/iter. Total: 0.0560 s/iter. ETA=0:00:46                            
[10/21 22:52:21 d2.evaluation.evaluator]: Inference done 400/1129. Dataloading: 0.0118 s/iter. Inference: 0.0407 s/iter. Eval: 0.0023 s/iter. Total: 0.0548 s/iter. ETA=0:00:39                            
[10/21 22:52:26 d2.evaluation.evaluator]: Inference done 499/1129. Dataloading: 0.0118 s/iter. Inference: 0.0399 s/iter. Eval: 0.0023 s/iter. Total: 0.0540 s/iter. ETA=0:00:34                            
[10/21 22:52:31 d2.evaluation.evaluator]: Inference done 595/1129. Dataloading: 0.0118 s/iter. Inference: 0.0396 s/iter. Eval: 0.0023 s/iter. Total: 0.0538 s/iter. ETA=0:00:28                            
[10/21 22:52:36 d2.evaluation.evaluator]: Inference done 695/1129. Dataloading: 0.0118 s/iter. Inference: 0.0392 s/iter. Eval: 0.0022 s/iter. Total: 0.0532 s/iter. ETA=0:00:23                            
[10/21 22:52:41 d2.evaluation.evaluator]: Inference done 794/1129. Dataloading: 0.0118 s/iter. Inference: 0.0389 s/iter. Eval: 0.0021 s/iter. Total: 0.0529 s/iter. ETA=0:00:17                            
[10/21 22:52:46 d2.evaluation.evaluator]: Inference done 892/1129. Dataloading: 0.0118 s/iter. Inference: 0.0387 s/iter. Eval: 0.0021 s/iter. Total: 0.0527 s/iter. ETA=0:00:12                            
[10/21 22:52:51 d2.evaluation.evaluator]: Inference done 989/1129. Dataloading: 0.0118 s/iter. Inference: 0.0386 s/iter. Eval: 0.0022 s/iter. Total: 0.0526 s/iter. ETA=0:00:07                            
[10/21 22:52:56 d2.evaluation.evaluator]: Inference done 1085/1129. Dataloading: 0.0118 s/iter. Inference: 0.0385 s/iter. Eval: 0.0022 s/iter. Total: 0.0526 s/iter. ETA=0:00:02                           
[10/21 22:52:58 d2.evaluation.evaluator]: Total inference time: 0:00:58.987842 (0.052480 s / iter per device, on 1 devices)                                                                                
[10/21 22:52:58 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:43 (0.038405 s / iter per device, on 1 devices)                                                                          
[10/21 22:52:58 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...                                                                                                                      
[10/21 22:52:58 d2.evaluation.coco_evaluation]: Saving results to output_1/inference/coco_instances_results.json                                                                                           
[10/21 22:52:58 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...                                                                                                         
Loading and preparing results...                                                                                                                                                                           
DONE (t=0.01s)                                                                                                                                                                                             
creating index...                                                                                                                                                                                          
index created!                                                                                                                                                                                             
[10/21 22:52:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*                                                                                                                              
[10/21 22:52:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.14 seconds.                                                                                                            
[10/21 22:52:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...                                                                                                                           
[10/21 22:52:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.                                                                                                          
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463                                                                                                                            
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.647                                                                                                                            
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.513                                                                                                                            
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.335                                                                                                                            
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.645                                                                                                                            
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.480                                                                                                                            
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.281                                                                                                                            
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.516                                                                                                                            
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529                                                                                                                            
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.359                                                                                                                            
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.694                                                                                                                            
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709                                                                                                                            
 Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=100 ] = 0.488                                                                                                                            
 Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=100 ] = 0.835                                                                                                                            
 Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=100 ] = 0.753                                                                                                                            
 Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=  1 ] = 0.344                                                                                                                            
 Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 10 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.710                                                                                                                            
 Average Recall     (AR) @[ IoU=0.50      | area= small | maxDets=100 ] = 0.536                                                                                                                            
 Average Recall     (AR) @[ IoU=0.50      | area=medium | maxDets=100 ] = 0.872
 Average Recall     (AR) @[ IoU=0.50      | area= large | maxDets=100 ] = 0.945
[10/21 22:52:58 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.326 | 64.729 | 51.310 | 33.508 | 64.507 | 48.011 |
Loading and preparing results...
DONE (t=0.10s)
creating index...
index created!
[10/21 22:52:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[10/21 22:52:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.34 seconds.
[10/21 22:52:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[10/21 22:52:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.038
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.122
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.248
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.103
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.221
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.348
 Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=100 ] = 0.424
 Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=100 ] = 0.451
 Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=100 ] = 0.706
 Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=  1 ] = 0.265
 Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 10 ] = 0.558
 Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.578
 Average Recall     (AR) @[ IoU=0.50      | area= small | maxDets=100 ] = 0.497
 Average Recall     (AR) @[ IoU=0.50      | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50      | area= large | maxDets=100 ] = 0.819
[10/21 22:52:59 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 14.058 | 44.489 | 3.758  | 15.967 | 12.243 | 24.793 |
[10/21 22:52:59 d2.engine.defaults]: Evaluation results for crack_val in csv format:
[10/21 22:52:59 d2.evaluation.testing]: copypaste: Task: bbox
[10/21 22:52:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[10/21 22:52:59 d2.evaluation.testing]: copypaste: 46.3261,64.7289,51.3104,33.5084,64.5071,48.0107
[10/21 22:52:59 d2.evaluation.testing]: copypaste: Task: segm
[10/21 22:52:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[10/21 22:52:59 d2.evaluation.testing]: copypaste: 14.0583,44.4888,3.7578,15.9666,12.2429,24.7931
[10/21 22:52:59 d2.utils.events]:  eta: 0:55:40  iter: 889849  epoch: 197.0  total_loss: 0.2642  loss_cls: 0.02684  loss_box_reg: 0.04411  loss_mask: 0.1502  loss_rpn_cls: 0.004566  loss_rpn_loc: 0.0142 
 time: 0.2457  data_time: 0.0364  lr: 0.001  max_mem: 0M
[10/21 23:11:47 d2.engine.hooks]: Saved best model as latest eval score for segm/AP50 is 44.48877, better than last best score 42.67217 @ iteration 740787.

# above score threshold 0.05 mask_threshold 0.5

# score threshold 0.7 mask_threshold 0.5
OrderedDict([('bbox', {'AP': 43.44768089025816, 'AP50': 59.41531579530026, 'AP75': 48.39560150751844, 'APs': 29.256475544024585, 'APm': 62.10693771790835, 'APl': 52.02358887812273}), ('segm', {'AP': 11.243301449236833, 'AP50': 36.154228951921105, 'AP75': 2.7433082220090097, 'APs': 12.06564699246864, 'APm': 9.73021365110075, 'APl': 24.92154290712657})])

# score threshold 0.8 mask_threshold 0.5
OrderedDict([('bbox', {'AP': 42.79117804707413, 'AP50': 58.61725748383964, 'AP75': 47.72071977785941, 'APs': 28.395171168732386, 'APm': 61.32009660234581, 'APl': 52.02358887812273}), ('segm', {'AP': 10.98634215499895, 'AP50': 34.9296943647248, 'AP75': 2.7433082220090097, 'APs': 11.759461870619766, 'APm': 9.513120436477223, 'APl': 24.92154290712657})])

# score threshold 0.9 mask_threshold 0.5 512
OrderedDict([('bbox', {'AP': 41.43740178806618, 'AP50': 55.316857684769985, 'AP75': 47.007606197313365, 'APs': 26.76304779450413, 'APm': 60.31602591566293, 'APl': 51.2162929109368}), ('segm', {'AP': 10.546251685145572, 'AP50': 33.66396450988604, 'AP75': 2.5950581028794497, 'APs': 11.093442330645546, 'APm': 9.263171886450996, 'APl': 24.578149038755573})])

# score threshold 0.9 mask_threshold 0.5 1024
OrderedDict([('bbox', {'AP': 41.124162703916404, 'AP50': 55.642634540074965, 'AP75': 46.10889139135666, 'APs': 27.583959964662423, 'APm': 57.22268464241318, 'APl': 50.270086842874505}), ('segm', {'AP': 12.86801146633374, 'AP50': 37.42194604325856, 'AP75': 3.984846410335026, 'APs': 13.849464432968853, 'APm': 10.58881639483933, 'APl': 23.418400008502648})])

# score threshold 0.9 mask_threshold 0.4 1024
OrderedDict([('bbox', {'AP': 41.124162703916404, 'AP50': 55.642634540074965, 'AP75': 46.10889139135666, 'APs': 27.583959964662423, 'APm': 57.22268464241318, 'APl': 50.270086842874505}), ('segm', {'AP': 13.537214573991625, 'AP50': 40.21958663778184, 'AP75': 3.7200043823475193, 'APs': 14.478269801160017, 'APm': 11.646315796500218, 'APl': 23.06838228772278})])

# score threshold 0.9 mask_threshold 0.3 1024
OrderedDict([('bbox', {'AP': 41.124162703916404, 'AP50': 55.642634540074965, 'AP75': 46.10889139135666, 'APs': 27.583959964662423, 'APm': 57.22268464241318, 'APl': 50.270086842874505}), ('segm', {'AP': 11.633138111010197, 'AP50': 38.539590555363404, 'AP75': 1.8281144636754267, 'APs': 12.80062974431787, 'APm': 9.61141547308439, 'APl': 19.728402686236443})])

# score threshold 0.05 mask_threshold 0.5 1024
OrderedDict([('bbox', {'AP': 45.18893868725593, 'AP50': 64.75295136460774, 'AP75': 49.14035220162328, 'APs': 32.34368302459321, 'APm': 61.70069272927338, 'APl': 52.79770908852527}), ('segm', {'AP': 14.345005128574028, 'AP50': 42.798789471545305, 'AP75': 4.244693066884627, 'APs': 15.89742065548779, 'APm': 11.474062840736961, 'APl': 24.562106267049966})])

# score threshold 0.05 mask_threshold 0.4 1024
OrderedDict([('bbox', {'AP': 45.18893868725593, 'AP50': 64.75295136460774, 'AP75': 49.14035220162328, 'APs': 32.34368302459321, 'APm': 61.70069272927338, 'APl': 52.79770908852527}), ('segm', {'AP': 15.135299194453172, 'AP50': 45.951012764414514, 'AP75': 3.9594828971983915, 'APs': 16.62779505209572, 'APm': 12.663652211068243, 'APl': 24.673262604441042})])

# score threshold 0.05 mask_threshold 0.3 1024
OrderedDict([('bbox', {'AP': 45.18893868725593, 'AP50': 64.75295136460774, 'AP75': 49.14035220162328, 'APs': 32.34368302459321, 'APm': 61.70069272927338, 'APl': 52.79770908852527}), ('segm', {'AP': 13.067039793960353, 'AP50': 44.282662128338444, 'AP75': 1.9443280327514527, 'APs': 14.816171757270446, 'APm': 10.499529187073213, 'APl': 21.154667804747355})])

# score threshold 0.7 mask_threshold 0.4 1024
OrderedDict([('bbox', {'AP': 42.88821056272011, 'AP50': 59.59284146358635, 'AP75': 47.46524460523407, 'APs': 29.67851961767223, 'APm': 58.96766098647939, 'APl': 51.60992656412509}), ('segm', {'AP': 14.185106952978991, 'AP50': 42.14691715681095, 'AP75': 3.879276638687077, 'APs': 15.48837809234328, 'APm': 12.023592608207924, 'APl': 23.61763800653493})])